{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ae0b39f-7a82-41e6-a12a-30309ecae401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  \n",
    "from joblib import dump\n",
    "from sklearn.base import clone\n",
    "\n",
    "DATA_ROOT = r\"data\"   \n",
    "\n",
    "SENSOR_FOLDERS = {\n",
    "    \"act\": \"act\",\n",
    "    \"acw\": \"acw\",\n",
    "    \"pm\":  \"pm_1.0_1.0\",\n",
    "    \"dc\":  \"dc_0.05_0.05\",\n",
    "}\n",
    "\n",
    "FNAME_RE = re.compile(r\"(?P<ex>\\d{2})_(?P<sensor>[a-z]+)_(?:\\d+)\\.csv$\", re.IGNORECASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e374b17-fe06-443d-af45-5f365cb29956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file_info(path):\n",
    "    fname = os.path.basename(path)\n",
    "    m = FNAME_RE.search(fname)\n",
    "    if not m:\n",
    "        return None\n",
    "    ex = int(m.group(\"ex\"))               \n",
    "    sensor = m.group(\"sensor\").lower()  \n",
    "    subject = int(os.path.basename(os.path.dirname(path)))  \n",
    "    return {\"subject\": subject, \"exercise_id\": ex, \"sensor_tag\": sensor, \"path\": path}\n",
    "\n",
    "def collect_files(sensor_key):\n",
    "    folder = os.path.join(DATA_ROOT, SENSOR_FOLDERS[sensor_key])\n",
    "    paths = glob.glob(os.path.join(folder, \"*\", \"*.csv\"))\n",
    "    infos = []\n",
    "    for p in sorted(paths):\n",
    "        info = parse_file_info(p)\n",
    "        if info is None:\n",
    "            continue\n",
    "        infos.append(info)\n",
    "    return pd.DataFrame(infos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d4f0da4-d758-475f-85e4-006c755368aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_act_acw_csv(path):\n",
    "    df = pd.read_csv(path, header=None)\n",
    "\n",
    "    if df.shape[1] < 4:\n",
    "        return None, None\n",
    "\n",
    "    t = df.iloc[:, 0].astype(str).to_numpy()\n",
    "    M = df.iloc[:, 1:4].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    if M.isna().mean().mean() > 0.01:\n",
    "        return None, None\n",
    "\n",
    "    return t, M.to_numpy(dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ddf05a2d-016c-458b-b01c-ff66f5ef2cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pm_dc_csv(path):\n",
    "    df = pd.read_csv(path, header=None)\n",
    "\n",
    "    if df.shape[1] < 3:\n",
    "        return None, None\n",
    "\n",
    "    t = df.iloc[:, 0].astype(str).to_numpy()\n",
    "    M = df.iloc[:, 1:].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    M = M.dropna(axis=1, how=\"all\")\n",
    "    if M.shape[1] == 0:\n",
    "        return None, None\n",
    "\n",
    "    M = M.interpolate(limit_direction=\"both\").bfill().ffill()\n",
    "    return t, M.to_numpy(dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3d97f52-e1e3-4706-9d61-cf613d350e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feats_act_like(M, prefix):\n",
    "    if M.shape[1] < 3:\n",
    "        return {}\n",
    "\n",
    "    x, y, z = M[:, 0], M[:, 1], M[:, 2]\n",
    "    mag = np.sqrt(x*x + y*y + z*z)\n",
    "\n",
    "    def stats(v, name):\n",
    "        return {\n",
    "            f\"{prefix}__{name}_mean\": float(np.mean(v)),\n",
    "            f\"{prefix}__{name}_std\":  float(np.std(v)),\n",
    "            f\"{prefix}__{name}_min\":  float(np.min(v)),\n",
    "            f\"{prefix}__{name}_max\":  float(np.max(v)),\n",
    "            f\"{prefix}__{name}_med\":  float(np.median(v)),\n",
    "            f\"{prefix}__{name}_iqr\":  float(np.percentile(v, 75) - np.percentile(v, 25)),\n",
    "            f\"{prefix}__{name}_skew\": float(skew(v)) if len(v) > 2 else 0.0,\n",
    "            f\"{prefix}__{name}_kurt\": float(kurtosis(v, fisher=True)) if len(v) > 3 else 0.0,\n",
    "            f\"{prefix}__{name}_energy\": float(np.mean(v*v)),\n",
    "        }\n",
    "\n",
    "    feats = {}\n",
    "    feats.update(stats(x, \"x\"))\n",
    "    feats.update(stats(y, \"y\"))\n",
    "    feats.update(stats(z, \"z\"))\n",
    "    feats.update(stats(mag, \"mag\"))\n",
    "\n",
    "    feats[f\"{prefix}__corr_xy\"] = float(np.corrcoef(x, y)[0, 1]) if np.std(x) > 0 and np.std(y) > 0 else 0.0\n",
    "    feats[f\"{prefix}__corr_xz\"] = float(np.corrcoef(x, z)[0, 1]) if np.std(x) > 0 and np.std(z) > 0 else 0.0\n",
    "    feats[f\"{prefix}__corr_yz\"] = float(np.corrcoef(y, z)[0, 1]) if np.std(y) > 0 and np.std(z) > 0 else 0.0\n",
    "\n",
    "    feats[f\"{prefix}__T\"] = int(M.shape[0])\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0865e1b7-9349-47ed-9a22-adb9fe30706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feats_frame_sensor(M, prefix, maxval=1.0):\n",
    "    if M.size == 0:\n",
    "        return {}\n",
    "\n",
    "    frame_mean   = M.mean(axis=1)\n",
    "    frame_std    = M.std(axis=1)\n",
    "    frame_energy = (M*M).mean(axis=1)\n",
    "\n",
    "    thr = 0.05 * maxval\n",
    "    frame_active = (M > thr).mean(axis=1)   \n",
    "\n",
    "    flat = M.ravel()\n",
    "\n",
    "    def agg(v, name):\n",
    "        return {\n",
    "            f\"{prefix}__{name}_mean\": float(np.mean(v)),\n",
    "            f\"{prefix}__{name}_std\":  float(np.std(v)),\n",
    "            f\"{prefix}__{name}_min\":  float(np.min(v)),\n",
    "            f\"{prefix}__{name}_max\":  float(np.max(v)),\n",
    "            f\"{prefix}__{name}_med\":  float(np.median(v)),\n",
    "            f\"{prefix}__{name}_iqr\":  float(np.percentile(v, 75) - np.percentile(v, 25)),\n",
    "        }\n",
    "\n",
    "    feats = {}\n",
    "    feats[f\"{prefix}__T\"] = int(M.shape[0])\n",
    "    feats[f\"{prefix}__P\"] = int(M.shape[1])\n",
    "\n",
    "    feats.update(agg(flat, \"g\"))\n",
    "\n",
    "    feats.update(agg(frame_mean, \"frame_mean\"))\n",
    "    feats.update(agg(frame_std, \"frame_std\"))\n",
    "    feats.update(agg(frame_energy, \"frame_energy\"))\n",
    "    feats.update(agg(frame_active, \"frame_active\"))\n",
    "\n",
    "    if M.shape[0] > 1:\n",
    "        frame_diff = np.abs(np.diff(M, axis=0)).mean(axis=1)  # (T-1,)\n",
    "        feats.update(agg(frame_diff, \"frame_diff\"))\n",
    "    else:\n",
    "        feats.update(agg(np.array([0.0]), \"frame_diff\"))\n",
    "\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "115ff589-25fa-4e5f-8bcb-72a284123b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_for_file(path, sensor_key):\n",
    "    if sensor_key in [\"act\", \"acw\"]:\n",
    "        t, M = read_act_acw_csv(path)\n",
    "        if M is None:\n",
    "            return None\n",
    "        return feats_act_like(M, prefix=sensor_key)\n",
    "\n",
    "    if sensor_key in [\"pm\", \"dc\"]:\n",
    "        t, M = read_pm_dc_csv(path)\n",
    "        if M is None:\n",
    "            return None\n",
    "        return feats_frame_sensor(M, prefix=sensor_key, maxval=1.0)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_feature_table(sensor_key):\n",
    "    meta = collect_files(sensor_key)\n",
    "    rows = []\n",
    "    skipped = 0\n",
    "\n",
    "    for _, r in meta.iterrows():\n",
    "        feats = extract_features_for_file(r[\"path\"], sensor_key)\n",
    "        if feats is None or len(feats) == 0:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        row = {}\n",
    "        row.update(feats)  \n",
    "        row[\"subject\"] = int(r[\"subject\"])\n",
    "        row[\"exercise_id\"] = int(r[\"exercise_id\"])\n",
    "        row[\"path\"] = r[\"path\"]\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    if len(rows) == 0:\n",
    "        print(f\"[{sensor_key}] WARNING: 0 rows. Check DATA_ROOT and file parsing.\")\n",
    "        df = pd.DataFrame(columns=[\"subject\",\"exercise_id\",\"path\"])\n",
    "    else:\n",
    "        df = pd.DataFrame(rows)\n",
    "\n",
    "    print(f\"[{sensor_key}] rows={len(df)} skipped={skipped} total_files={len(meta)}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99315037-9d32-440d-9d5d-77b19e164646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[act] rows=239 skipped=0 total_files=239\n",
      "[acw] rows=239 skipped=0 total_files=239\n",
      "[pm] rows=239 skipped=0 total_files=239\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m acw_df \u001b[38;5;241m=\u001b[39m build_feature_table(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m pm_df  \u001b[38;5;241m=\u001b[39m build_feature_table(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m dc_df  \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_feature_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(act_df\u001b[38;5;241m.\u001b[39mshape, acw_df\u001b[38;5;241m.\u001b[39mshape, pm_df\u001b[38;5;241m.\u001b[39mshape, dc_df\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[45], line 23\u001b[0m, in \u001b[0;36mbuild_feature_table\u001b[0;34m(sensor_key)\u001b[0m\n\u001b[1;32m     20\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, r \u001b[38;5;129;01min\u001b[39;00m meta\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 23\u001b[0m     feats \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features_for_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msensor_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(feats) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     25\u001b[0m         skipped \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[45], line 9\u001b[0m, in \u001b[0;36mextract_features_for_file\u001b[0;34m(path, sensor_key)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m feats_act_like(M, prefix\u001b[38;5;241m=\u001b[39msensor_key)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sensor_key \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m----> 9\u001b[0m     t, M \u001b[38;5;241m=\u001b[39m \u001b[43mread_pm_dc_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m M \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m, in \u001b[0;36mread_pm_dc_csv\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_pm_dc_csv\u001b[39m(path):\n\u001b[0;32m----> 2\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "act_df = build_feature_table(\"act\")\n",
    "acw_df = build_feature_table(\"acw\")\n",
    "pm_df  = build_feature_table(\"pm\")\n",
    "dc_df  = build_feature_table(\"dc\")\n",
    "print(act_df.shape, acw_df.shape, pm_df.shape, dc_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3e42ac-12ad-4e21-8f4b-c7e37ca29991",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc88254f-672b-479f-a925-03354836391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213f1555-1521-4743-9a42-f14d154f4e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "acw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5bc48-b86a-41ad-b905-5d43f5e3b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04fbf82-03b7-4cb1-8797-b5ff87b18c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_modalities_left(base_df, other_dfs: dict):\n",
    "    keys = [\"subject\", \"exercise_id\"]\n",
    "\n",
    "    feat_cols = [c for c in base_df.columns if c not in keys + [\"path\"]]\n",
    "    merged = base_df[keys + feat_cols].copy()\n",
    "\n",
    "    for name, df in other_dfs.items():\n",
    "        if df is None or df.shape[0] == 0:\n",
    "            print(f\"[merge] {name} empty -> skipped\")\n",
    "            continue\n",
    "\n",
    "        feat_cols = [c for c in df.columns if c not in keys + [\"path\"]]\n",
    "        keep = df[keys + feat_cols].copy()\n",
    "        merged = merged.merge(keep, on=keys, how=\"left\")\n",
    "\n",
    "    return merged\n",
    "\n",
    "# Full feature set (ALL sensors): ACT + ACW + PM + DC\n",
    "df_all = merge_modalities_left(act_df, {\"acw\": acw_df, \"pm\": pm_df, \"dc\": dc_df})\n",
    "print(\"ALL sensors shape:\", df_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c59cdd4-2a0d-4d37-a50c-ac18b20d7b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "# Save raw (feature-engineered) table for reproducibility\n",
    "df_all.to_csv(\"outputs/mex_features_all_raw.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9188f224-0a4f-4ffd-a8fc-1933d69c434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bffbc49-0852-4cba-a277-d87eb096ff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all\n",
    "df_all.info()\n",
    "df_all['exercise_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643cc256-b365-4da2-88fe-58a41f18e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_pre = df_all.copy()\n",
    "num_cols = df_all_pre.select_dtypes(include=[np.number]).columns\n",
    "df_all_pre[num_cols] = df_all_pre[num_cols].replace([np.inf, -np.inf], np.nan)\n",
    "df_all_pre[num_cols] = df_all_pre[num_cols].fillna(df_all_pre[num_cols].median(numeric_only=True))\n",
    "\n",
    "df_all_pre.to_csv(\"outputs/mex_features_all_preprocessed.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" - outputs/mex_features_all_raw.csv\")\n",
    "print(\" - outputs/mex_features_all_preprocessed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e15afc-3cdc-46eb-be43-60b7b3ac8600",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01c3f5c-d2d5-433e-a2ec-00a9ff0ae1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_all_pre.drop(columns=[\"exercise_id\",\"subject\",\"path\"], errors=\"ignore\")\n",
    "X = X.select_dtypes(include=[np.number]) \n",
    "y = df_all_pre[\"exercise_id\"].values\n",
    "groups = df_all_pre[\"subject\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aecb494-346d-4a6e-8d61-9c564de0b168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "\n",
    "def plot_pca_2d(X, y, title=\"PCA 2D projekcija\", sample=5000, random_state=0):\n",
    "    if sample is not None and X.shape[0] > sample:\n",
    "        rng = np.random.default_rng(random_state)\n",
    "        idx = rng.choice(X.shape[0], size=sample, replace=False)\n",
    "        Xp, yp = X.iloc[idx], y[idx]\n",
    "    else:\n",
    "        Xp, yp = X, y\n",
    "\n",
    "    Xs = StandardScaler().fit_transform(Xp)\n",
    "    Z = PCA(n_components=2, random_state=random_state).fit_transform(Xs)\n",
    "\n",
    "    plt.figure(figsize=(7,5))\n",
    "    for lab in sorted(np.unique(yp)):\n",
    "        m = (yp == lab)\n",
    "        plt.scatter(Z[m,0], Z[m,1], s=12, alpha=0.7, label=str(lab))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_pca_3d(X, y, title=\"PCA 3D projekcija\", sample=5000, random_state=0):\n",
    "    if sample is not None and X.shape[0] > sample:\n",
    "        rng = np.random.default_rng(random_state)\n",
    "        idx = rng.choice(X.shape[0], size=sample, replace=False)\n",
    "        Xp, yp = X.iloc[idx], y[idx]\n",
    "    else:\n",
    "        Xp, yp = X, y\n",
    "\n",
    "    Xs = StandardScaler().fit_transform(Xp)\n",
    "    Z = PCA(n_components=3, random_state=random_state).fit_transform(Xs)\n",
    "\n",
    "    fig = plt.figure(figsize=(7,5))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for lab in sorted(np.unique(yp)):\n",
    "        m = (yp == lab)\n",
    "        ax.scatter(Z[m,0], Z[m,1], Z[m,2], s=12, alpha=0.7, label=str(lab))\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"PC1\"); ax.set_ylabel(\"PC2\"); ax.set_zlabel(\"PC3\")\n",
    "    ax.legend(bbox_to_anchor=(1.25, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd3aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X:\", X.shape, \"| broj klasa:\", len(np.unique(y)))\n",
    "\n",
    "# Obavezno iz zadatka: vizuelni prikaz (2D/3D) -> koristimo PCA projekciju\n",
    "plot_pca_2d(X, y, title=\"MEx: PCA 2D projekcija (svi atributi)\")\n",
    "plot_pca_3d(X, y, title=\"MEx: PCA 3D projekcija (svi atributi)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13883e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eba279",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cad005b-8ee1-4c08-b028-e513a7cdc6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_all = PCA(random_state=0).fit(X_train_sc)\n",
    "cum_var = np.cumsum(pca_all.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(cum_var)\n",
    "plt.axhline(0.90, linestyle=\"--\")\n",
    "plt.axhline(0.95, linestyle=\"--\")\n",
    "plt.xlabel(\"Broj komponenti\")\n",
    "plt.ylabel(\"Kumulativna očuvana varijansa\")\n",
    "plt.title(\"PCA - izbor dimenzionalnosti preko varijanse (train)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "pca90 = PCA(n_components=0.90, random_state=0)\n",
    "X_train_pca90 = pca90.fit_transform(X_train_sc)\n",
    "X_test_pca90  = pca90.transform(X_test_sc)\n",
    "\n",
    "pca95 = PCA(n_components=0.95, random_state=0)\n",
    "X_train_pca95 = pca95.fit_transform(X_train_sc)\n",
    "X_test_pca95  = pca95.transform(X_test_sc)\n",
    "\n",
    "print(\"PCA90 dim:\", X_train_pca90.shape[1], \"| PCA95 dim:\", X_train_pca95.shape[1])\n",
    "\n",
    "kbest50 = SelectKBest(mutual_info_classif, k=min(50, X_train_sc.shape[1]))\n",
    "X_train_kb50 = kbest50.fit_transform(X_train_sc, y_train)\n",
    "X_test_kb50  = kbest50.transform(X_test_sc)\n",
    "\n",
    "print(\"Shapes:\",\n",
    "      \"full\", X_train_sc.shape,\n",
    "      \"| pca90\", X_train_pca90.shape,\n",
    "      \"| pca95\", X_train_pca95.shape,\n",
    "      \"| kbest50\", X_train_kb50.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d8b98-46f9-4f9a-86d9-bbb6b604e649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "MODELS = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=3000, C=0.01),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200,max_depth=8,min_samples_leaf=5,random_state=42),\n",
    "    \"SVM (RBF)\": SVC(kernel=\"rbf\"),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d41cfa-9f2d-450e-910c-0b490b41731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from IPython.display import display\n",
    "\n",
    "variants = {\n",
    "    \"Full (svi atributi)\": (X_train_sc, X_test_sc),\n",
    "    \"PCA90 (90% varijanse)\": (X_train_pca90, X_test_pca90),\n",
    "    \"PCA95 (95% varijanse)\": (X_train_pca95, X_test_pca95),\n",
    "    \"KBest50 (mutual_info)\": (X_train_kb50, X_test_kb50),\n",
    "}\n",
    "\n",
    "\n",
    "def eval_model(name, model, Xtr, Xte, ytr, yte, variant_name=\"\", show_cm=True):\n",
    "    model.fit(Xtr, ytr)\n",
    "\n",
    "    pred_tr = model.predict(Xtr)\n",
    "    pred_te = model.predict(Xte)\n",
    "\n",
    "    out = {\n",
    "        \"Algoritam\": name,\n",
    "        \"Train Accuracy\": float(accuracy_score(ytr, pred_tr)),\n",
    "        \"Train F1-macro\": float(f1_score(ytr, pred_tr, average=\"macro\")),\n",
    "        \"Test Accuracy\": float(accuracy_score(yte, pred_te)),\n",
    "        \"Test F1-macro\": float(f1_score(yte, pred_te, average=\"macro\")),\n",
    "    }\n",
    "\n",
    "    if show_cm:\n",
    "        print(f\"\\n--- {name} ---\")\n",
    "        print(\"Train acc:\", round(out[\"Train Accuracy\"],4), \"| Test acc:\", round(out[\"Test Accuracy\"],4))\n",
    "\n",
    "        # TRAIN CM\n",
    "        labels = getattr(model, \"classes_\", None)\n",
    "        if labels is None:\n",
    "            labels = np.unique(np.concatenate([ytr, pred_tr]))\n",
    "        cm_tr = confusion_matrix(ytr, pred_tr, labels=labels)\n",
    "        disp_tr = ConfusionMatrixDisplay(confusion_matrix=cm_tr, display_labels=labels)\n",
    "        disp_tr.plot(cmap=\"viridis\", values_format=\"d\", colorbar=True)\n",
    "        plt.title(f\"Train {variant_name} | {name}\")\n",
    "        plt.xlabel(\"Predicted label\")\n",
    "        plt.ylabel(\"True label\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # TEST CM\n",
    "        labels = getattr(model, \"classes_\", None)\n",
    "        if labels is None:\n",
    "            labels = np.unique(np.concatenate([yte, pred_te]))\n",
    "        cm_te = confusion_matrix(yte, pred_te, labels=labels)\n",
    "        disp_te = ConfusionMatrixDisplay(confusion_matrix=cm_te, display_labels=labels)\n",
    "        disp_te.plot(cmap=\"viridis\", values_format=\"d\", colorbar=True)\n",
    "        plt.title(f\"Test {variant_name} | {name}\")\n",
    "        plt.xlabel(\"Predicted label\")\n",
    "        plt.ylabel(\"True label\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return out\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for variant_name, (Xtr, Xte) in variants.items():\n",
    "    print(\"\\n===============================\")\n",
    "    print(\"VARIJANTA:\", variant_name)\n",
    "    print(\"===============================\")\n",
    "\n",
    "    for mname, model in MODELS.items():\n",
    "        metrics = eval_model(mname, model, Xtr, Xte, y_train, y_test, variant_name=variant_name, show_cm=True)\n",
    "        metrics[\"Varijanta\"] = variant_name\n",
    "        all_results.append(metrics)\n",
    "\n",
    "res_df = pd.DataFrame(all_results)\n",
    "res_df[\"Test Accuracy\"] = res_df[\"Test Accuracy\"].round(4)\n",
    "res_df[\"Test F1-macro\"] = res_df[\"Test F1-macro\"].round(4)\n",
    "res_df[\"Train Accuracy\"] = res_df[\"Train Accuracy\"].round(4)\n",
    "res_df[\"Train F1-macro\"] = res_df[\"Train F1-macro\"].round(4)\n",
    "\n",
    "res_df.sort_values([\"Varijanta\", \"Test F1-macro\", \"Test Accuracy\"], ascending=[True, False, False])\n",
    "\n",
    "best_overall = (res_df\n",
    "    .sort_values([\"Test F1-macro\",\"Test Accuracy\"], ascending=[False, False])\n",
    "    .head(1)\n",
    ")\n",
    "\n",
    "display(best_overall[[\"Varijanta\",\"Algoritam\",\"Test F1-macro\",\"Test Accuracy\",\"Train F1-macro\",\"Train Accuracy\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab974082-ce37-4419-b09e-bfa028c4627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Najbolji model po varijanti (po Test F1-macro pa Test Accuracy)\n",
    "best_per_variant = (res_df\n",
    "    .sort_values([\"Varijanta\", \"Test F1-macro\", \"Test Accuracy\"], ascending=[True, False, False])\n",
    "    .groupby(\"Varijanta\", as_index=False)\n",
    "    .first()\n",
    ")\n",
    "\n",
    "best_per_variant[[\"Varijanta\",\"Algoritam\",\"Test F1-macro\",\"Test Accuracy\",\"Train F1-macro\",\"Train Accuracy\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575563fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": [0.1, 1, 10, 50],\n",
    "    \"kernel\": [\"rbf\", \"linear\"],\n",
    "    \"gamma\": [\"scale\", \"auto\"],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=SVC(),\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train_pca95, y_train)\n",
    "\n",
    "print(\"Najbolji parametri:\", grid.best_params_)\n",
    "print(\"Najbolji CV F1-macro:\", round(grid.best_score_, 4))\n",
    "\n",
    "best_svm = grid.best_estimator_\n",
    "\n",
    "_ = eval_model(\"SVM (GridSearch best) @ PCA95\", best_svm, X_train_pca95, X_test_pca95, y_train, y_test, show_cm=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f70ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib, os\n",
    "from sklearn.base import clone\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "res_df.to_csv(\"outputs/model_results_all.csv\", index=False)\n",
    "best_per_variant.to_csv(\"outputs/best_per_variant.csv\", index=False)\n",
    "best_overall.to_csv(\"outputs/best_overall.csv\", index=False)\n",
    "\n",
    "joblib.dump(scaler, \"outputs/scaler.joblib\")\n",
    "joblib.dump(pca90, \"outputs/pca90.joblib\")\n",
    "joblib.dump(pca95, \"outputs/pca95.joblib\")\n",
    "joblib.dump(kbest50, \"outputs/kbest50_selector.joblib\")\n",
    "\n",
    "best_row = best_overall.iloc[0]\n",
    "best_variant = best_row[\"Varijanta\"]\n",
    "best_alg = best_row[\"Algoritam\"]\n",
    "\n",
    "Xtr_best, Xte_best = variants[best_variant]\n",
    "best_model = clone(MODELS[best_alg])\n",
    "best_model.fit(Xtr_best, y_train)\n",
    "joblib.dump(best_model, f\"outputs/best_model_overall__{best_variant}__{best_alg}.joblib\")\n",
    "\n",
    "for _, row in best_per_variant.iterrows():\n",
    "    v = row[\"Varijanta\"]\n",
    "    a = row[\"Algoritam\"]\n",
    "    Xtr_v, Xte_v = variants[v]\n",
    "    m = clone(MODELS[a])\n",
    "    m.fit(Xtr_v, y_train)\n",
    "    joblib.dump(m, f\"outputs/best_model__{v}__{a}.joblib\")\n",
    "\n",
    "print(\"Sačuvano u outputs/: rezultati + scaler/PCA/KBest + najbolji modeli.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
